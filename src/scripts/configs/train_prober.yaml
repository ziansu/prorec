dualencoder_name_or_path: PurCL/casp-moco-lmpa-c-only
dualencoder_subfolder: checkpoint-17000
asm_tokenizer_name_or_path: PurCL/longcodeart-ep0.3-block200-26m
src_model_name_or_path: codellama/CodeLlama-7b-hf
# asm_feature_select_strategy: all
asm_feature_select_strategy: nodes
output_dir: ../save/src_prober_codellama-7b-last1unfreeze
hub_model_id: PurCL/src_prober_codellama-7b-last1unfreeze
dataset_name: PurCL/lmpa-prober-alignment
run_name: prober-codellama-7b-last1unfreeze

max_seq_length: 512

max_eval_samples: 2000 # debug

per_device_train_batch_size: 8
gradient_accumulation_steps: 4
per_device_eval_batch_size: 32

dataloader_num_workers: 8
remove_unused_columns: false
do_train: true
do_eval: true
do_predict: false

overwrite_cache: false

# Training
num_train_epochs: 5
learning_rate: 0.00005
warmup_steps: 1000
weight_decay: 0.01
lr_scheduler_type: cosine
evaluation_strategy: steps
eval_steps: 500
save_steps: 500
logging_steps: 10
save_total_limit: 1

# Out
report_to: wandb
cache_dir: ../save/.cache
push_to_hub: true
hub_private_repo: true
hub_strategy: all_checkpoints

overwrite_output_dir: true
# resume_from_checkpoint: true
torch_compile: false
fp16: true
# no_cuda: true